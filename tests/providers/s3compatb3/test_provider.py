import pytest

from tests.utils import MockCoroutine

import io
import time
import base64
import hashlib
from http import client
from unittest import mock

import boto3
from moto import mock_s3

import aiohttpretty

from waterbutler.core import streams
from waterbutler.core import metadata
from waterbutler.core import exceptions
from waterbutler.core.path import WaterButlerPath

from waterbutler.providers.s3compatb3 import S3CompatB3Provider
from waterbutler.providers.s3compatb3.metadata import S3CompatB3FileMetadata
from waterbutler.providers.s3compatb3.metadata import S3CompatB3FolderMetadata


@pytest.fixture
def auth():
    return {
        'name': 'cat',
        'email': 'cat@cat.com',
    }


@pytest.fixture
def credentials():
    return {
        'host': 'Target.Host',
        'access_key': 'Dont dead',
        'secret_key': 'open inside',
    }


@pytest.fixture
def settings():
    return {
        'bucket': 'that_kerning',
        'encrypt_uploads': False
    }

@pytest.fixture
def mock_time(monkeypatch):
    mock_time = mock.Mock(return_value=1454684930.0)
    monkeypatch.setattr(time, 'time', mock_time)


@pytest.fixture
def provider(auth, credentials, settings):
    # return S3CompatB3Provider(auth, credentials, settings)
    boto3.DEFAULT_SESSION = None
    with mock_s3():
        provider = S3CompatB3Provider(auth, credentials, settings)
        s3client = boto3.client('s3')
        s3client.create_bucket(Bucket=provider.bucket.name)
        s3 = boto3.resource('s3')
        provider.connection.s3 = s3
        provider.bucket = s3.Bucket(provider.bucket.name)
        return provider


@pytest.fixture
def file_content():
    return b'sleepy'


@pytest.fixture
def file_like(file_content):
    return io.BytesIO(file_content)


@pytest.fixture
def file_stream(file_like):
    return streams.FileStreamReader(file_like)


@pytest.fixture
def base_prefix():
    return ''

@pytest.fixture
def folder_metadata(base_prefix):
    return '''<?xml version="1.0" encoding="UTF-8"?>
        <ListBucketResult xmlns="http://s3.amazonaws.com/doc/2006-03-01/">
            <Name>bucket</Name>
            <Prefix/>
            <Marker/>
            <MaxKeys>1000</MaxKeys>
            <IsTruncated>false</IsTruncated>
            <Contents>
                <Key>{prefix}my-image.jpg</Key>
                <LastModified>2009-10-12T17:50:30.000Z</LastModified>
                <ETag>&quot;fba9dede5f27731c9771645a39863328&quot;</ETag>
                <Size>434234</Size>
                <StorageClass>STANDARD</StorageClass>
                <Owner>
                    <ID>75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a</ID>
                    <DisplayName>mtd@amazon.com</DisplayName>
                </Owner>
            </Contents>
            <Contents>
                <Key>{prefix}my-third-image.jpg</Key>
                <LastModified>2009-10-12T17:50:30.000Z</LastModified>
                <ETag>&quot;1b2cf535f27731c974343645a3985328&quot;</ETag>
                <Size>64994</Size>
                <StorageClass>STANDARD</StorageClass>
                <Owner>
                    <ID>75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a</ID>
                    <DisplayName>mtd@amazon.com</DisplayName>
                </Owner>
            </Contents>
            <CommonPrefixes>
                <Prefix>{prefix}   photos/</Prefix>
            </CommonPrefixes>
        </ListBucketResult>'''.format(prefix=base_prefix)


@pytest.fixture
def just_a_folder_metadata(base_prefix):
    return '''<?xml version="1.0" encoding="UTF-8"?>
        <ListBucketResult xmlns="http://s3.amazonaws.com/doc/2006-03-01/">
            <Name>bucket</Name>
            <Prefix/>
            <Marker/>
            <MaxKeys>1000</MaxKeys>
            <IsTruncated>false</IsTruncated>
            <Contents>
                <Key>{prefix}naptime/</Key>
                <LastModified>2009-10-12T17:50:30.000Z</LastModified>
                <ETag>&quot;fba9dede5f27731c9771645a39863328&quot;</ETag>
                <Size>0</Size>
                <StorageClass>STANDARD</StorageClass>
                <Owner>
                    <ID>75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a</ID>
                    <DisplayName>mtd@amazon.com</DisplayName>
                </Owner>
            </Contents>
        </ListBucketResult>'''.format(prefix=base_prefix)


@pytest.fixture
def contents_and_self(base_prefix):
    return '''<?xml version="1.0" encoding="UTF-8"?>
        <ListBucketResult xmlns="http://s3.amazonaws.com/doc/2006-03-01/">
            <Name>bucket</Name>
            <Prefix/>
            <Marker/>
            <MaxKeys>1000</MaxKeys>
            <IsTruncated>false</IsTruncated>
            <Contents>
                <Key>{prefix}thisfolder/</Key>
                <LastModified>2009-10-12T17:50:30.000Z</LastModified>
                <ETag>&quot;fba9dede5f27731c9771645a39863328&quot;</ETag>
                <Size>0</Size>
                <StorageClass>STANDARD</StorageClass>
                <Owner>
                    <ID>75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a</ID>
                    <DisplayName>mtd@amazon.com</DisplayName>
                </Owner>
            </Contents>
            <Contents>
                <Key>{prefix}thisfolder/item1</Key>
                <LastModified>2009-10-12T17:50:30.000Z</LastModified>
                <ETag>&quot;fba9dede5f27731c9771645a39863328&quot;</ETag>
                <Size>0</Size>
                <StorageClass>STANDARD</StorageClass>
                <Owner>
                    <ID>75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a</ID>
                    <DisplayName>mtd@amazon.com</DisplayName>
                </Owner>
            </Contents>
            <Contents>
                <Key>{prefix}thisfolder/item2</Key>
                <LastModified>2009-10-12T17:50:30.000Z</LastModified>
                <ETag>&quot;fba9dede5f27731c9771645a39863328&quot;</ETag>
                <Size>0</Size>
                <StorageClass>STANDARD</StorageClass>
                <Owner>
                    <ID>75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a</ID>
                    <DisplayName>mtd@amazon.com</DisplayName>
                </Owner>
            </Contents>
        </ListBucketResult>'''.format(prefix=base_prefix)


@pytest.fixture
def folder_empty_metadata():
    return b'''<?xml version="1.0" encoding="UTF-8"?>
        <ListBucketResult xmlns="http://s3.amazonaws.com/doc/2006-03-01/">
            <Name>bucket</Name>
            <Prefix/>
            <Marker/>
            <MaxKeys>1000</MaxKeys>
            <IsTruncated>false</IsTruncated>
        </ListBucketResult>'''


@pytest.fixture
def file_metadata():
    return {
        'Content-Length': 9001,
        'Last-Modified': 'SomeTime',
        'Content-Type': 'binary/octet-stream',
        'ETag': '"fba9dede5f27731c9771645a39863328"',
        'X-AMZ-SERVER-SIDE-ENCRYPTION': 'AES256'
    }


@pytest.fixture
def version_metadata():
    return b'''<?xml version="1.0" encoding="UTF-8"?>

    <ListVersionsResult xmlns="http://s3.amazonaws.com/doc/2006-03-01">
        <Name>bucket</Name>
        <Prefix>my</Prefix>
        <KeyMarker/>
        <VersionIdMarker/>
        <MaxKeys>5</MaxKeys>
        <IsTruncated>false</IsTruncated>
        <Version>
            <Key>my-image.jpg</Key>
            <VersionId>3/L4kqtJl40Nr8X8gdRQBpUMLUo</VersionId>
            <IsLatest>true</IsLatest>
            <LastModified>2009-10-12T17:50:30.000Z</LastModified>
            <ETag>&quot;fba9dede5f27731c9771645a39863328&quot;</ETag>
            <Size>434234</Size>
            <StorageClass>STANDARD</StorageClass>
            <Owner>
                <ID>75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a</ID>
                <DisplayName>mtd@amazon.com</DisplayName>
            </Owner>
        </Version>
        <Version>
            <Key>my-image.jpg</Key>
            <VersionId>QUpfdndhfd8438MNFDN93jdnJFkdmqnh893</VersionId>
            <IsLatest>false</IsLatest>
            <LastModified>2009-10-10T17:50:30.000Z</LastModified>
            <ETag>&quot;9b2cf535f27731c974343645a3985328&quot;</ETag>
            <Size>166434</Size>
            <StorageClass>STANDARD</StorageClass>
            <Owner>
                <ID>75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a</ID>
                <DisplayName>mtd@amazon.com</DisplayName>
            </Owner>
        </Version>
        <Version>
            <Key>my-image.jpg</Key>
            <VersionId>UIORUnfndfhnw89493jJFJ</VersionId>
            <IsLatest>false</IsLatest>
            <LastModified>2009-10-11T12:50:30.000Z</LastModified>
            <ETag>&quot;772cf535f27731c974343645a3985328&quot;</ETag>
            <Size>64</Size>
            <StorageClass>STANDARD</StorageClass>
            <Owner>
                <ID>75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a</ID>
                <DisplayName>mtd@amazon.com</DisplayName>
            </Owner>
        </Version>
    </ListVersionsResult>'''

def location_response(location):
    return (
        '<?xml version="1.0" encoding="UTF-8"?>\n'
        '<LocationConstraint xmlns="http://s3.amazonaws.com/doc/2006-03-01/">'
        '{}</LocationConstraint>'
    ).format(location)

def list_objects_response(keys, truncated=False):
    response = '''<?xml version="1.0" encoding="UTF-8"?>
    <ListBucketResult xmlns="http://s3.amazonaws.com/doc/2006-03-01/">
        <Name>bucket</Name>
        <Prefix/>
        <Marker/>
        <MaxKeys>1000</MaxKeys>'''

    response += '<IsTruncated>' + str(truncated).lower() + '</IsTruncated>'
    response += ''.join(map(
        lambda x: '<Contents><Key>{}</Key></Contents>'.format(x),
        keys
    ))

    response += '</ListBucketResult>'

    return response.encode('utf-8')

def bulk_delete_body(keys):
    payload = '<?xml version="1.0" encoding="UTF-8"?>'
    payload += '<Delete>'
    payload += ''.join(map(
        lambda x: '<Object><Key>{}</Key></Object>'.format(x),
        keys
    ))
    payload += '</Delete>'
    payload = payload.encode('utf-8')

    md5 = base64.b64encode(hashlib.md5(payload).digest())
    headers = {
        'Content-Length': str(len(payload)),
        'Content-MD5': md5.decode('ascii'),
        'Content-Type': 'text/xml',
    }

    return (payload, headers)

def build_folder_params(path):
    prefix = path.full_path.lstrip('/')
    return {'prefix': prefix, 'delimiter': '/'}


class TestProviderConstruction:

    def test_https(self, auth, credentials, settings):
        provider = S3CompatB3Provider(auth, {'host': 'securehost',
                                           'access_key': 'a',
                                           'secret_key': 's'}, settings)
        assert provider.connection.endpoint_url == 'https://securehost'

        provider = S3CompatB3Provider(auth, {'host': 'securehost:443',
                                           'access_key': 'a',
                                           'secret_key': 's'}, settings)
        assert provider.connection.endpoint_url == 'https://securehost'

    def test_http(self, auth, credentials, settings):
        provider = S3CompatB3Provider(auth, {'host': 'normalhost:80',
                                           'access_key': 'a',
                                           'secret_key': 's'}, settings)
        assert provider.connection.endpoint_url == 'http://normalhost'

        provider = S3CompatB3Provider(auth, {'host': 'normalhost:8080',
                                           'access_key': 'a',
                                           'secret_key': 's'}, settings)
        assert provider.connection.endpoint_url == 'http://normalhost'

    def test_region(self, auth, credentials, settings):
        provider = S3CompatB3Provider(auth, {'host': 'namespace.user.region1.oraclecloud.com',
                                           'access_key': 'a',
                                           'secret_key': 's'}, settings)
        assert provider.connection.region_name == 'region1'

        provider = S3CompatB3Provider(auth, {'host': 'securehost:443',
                                           'access_key': 'a',
                                           'secret_key': 's'}, settings)
        assert provider.connection.region_name == ''


class TestValidatePath:

    @pytest.mark.asyncio
    @pytest.mark.aiohttpretty
    async def test_validate_v1_path_file(self, provider, file_metadata, mock_time):
        file_path = 'foobah'
        full_path = file_path
        prefix = provider.prefix
        if prefix:
            full_path = prefix + full_path
        params_for_dir = {'prefix': full_path + '/', 'delimiter': '/'}

        assert WaterButlerPath('/') == await provider.validate_v1_path('/')

        with mock_s3():
            boto3.DEFAULT_SESSION = None
            s3client = boto3.client('s3')
            s3client.create_bucket(Bucket=provider.bucket.name)
            with pytest.raises(exceptions.NotFoundError) as exc:
                 await provider.validate_v1_path('/' + file_path)

        with mock_s3():
            boto3.DEFAULT_SESSION = None
            s3client = boto3.client('s3')
            s3client.create_bucket(Bucket=provider.bucket.name)
            s3client.put_object(Bucket=provider.bucket.name, Key=full_path)
            wb_path_v1 = await provider.validate_v1_path('/' + file_path)

        wb_path_v0 = await provider.validate_path('/' + file_path)

        assert wb_path_v1 == wb_path_v0

    @pytest.mark.asyncio
    @pytest.mark.aiohttpretty
    async def test_validate_v1_path_folder(self, provider, folder_metadata, mock_time):
        folder_path = 'Photos'
        full_path = folder_path
        prefix = provider.prefix
        if prefix:
            full_path = prefix + full_path

        with mock_s3():
            boto3.DEFAULT_SESSION = None
            s3client = boto3.client('s3')
            s3client.create_bucket(Bucket=provider.bucket.name)
            with pytest.raises(exceptions.NotFoundError) as exc:
                await provider.validate_v1_path('/' + folder_path + '/')

        with mock_s3():
            boto3.DEFAULT_SESSION = None
            s3client = boto3.client('s3')
            s3client.create_bucket(Bucket=provider.bucket.name)
            s3client.put_object(Bucket=provider.bucket.name, Key=full_path + '/')
            wb_path_v1 = await provider.validate_v1_path('/' + folder_path + '/')

        wb_path_v0 = await provider.validate_path('/' + folder_path + '/')

        assert wb_path_v1 == wb_path_v0

    @pytest.mark.asyncio
    async def test_normal_name(self, provider, mock_time):
        path = await provider.validate_path('/this/is/a/path.txt')
        assert path.name == 'path.txt'
        assert path.parent.name == 'a'
        assert path.is_file
        assert not path.is_dir
        assert not path.is_root

    @pytest.mark.asyncio
    async def test_folder(self, provider, mock_time):
        path = await provider.validate_path('/this/is/a/folder/')
        assert path.name == 'folder'
        assert path.parent.name == 'a'
        assert not path.is_file
        assert path.is_dir
        assert not path.is_root

    @pytest.mark.asyncio
    async def test_root(self, provider, mock_time):
        path = await provider.validate_path('/this/is/a/folder/')
        assert path.name == 'folder'
        assert path.parent.name == 'a'
        assert not path.is_file
        assert path.is_dir
        assert not path.is_root


class TestCRUD:

    @pytest.mark.asyncio
    @pytest.mark.aiohttpretty
    async def test_download(self, provider, mock_time):
        path = WaterButlerPath('/muhtriangle', prepend=provider.prefix)
        # url = provider.bucket.new_key(path.full_path).generate_url(100, response_headers={'response-content-disposition': 'attachment'})
        query_parameters = {'Bucket': provider.bucket.name, 'Key': path.full_path}
        url = provider.connection.s3.meta.client.generate_presigned_url('get_object', Params=query_parameters, ExpiresIn=100, HttpMethod='GET')
        # aiohttpretty.register_uri('GET', url[:url.index('?')], body=b'delicious', auto_length=True)
        aiohttpretty.register_uri('GET', url, body=b'delicious', auto_length=True)

        result = await provider.download(path)
        content = await result.read()

        assert content == b'delicious'

    @pytest.mark.asyncio
    @pytest.mark.aiohttpretty
    async def test_download_version(self, provider, mock_time):
        path = WaterButlerPath('/muhtriangle', prepend=provider.prefix)
        # url = provider.bucket.new_key(path.full_path).generate_url(
        #     100,
        #     query_parameters={'versionId': 'someversion'},
        #     response_headers={'response-content-disposition': 'attachment'},
        # )
        query_parameters = {'Bucket': provider.bucket.name, 'Key': path.full_path, 'VersionId': 'someversion'}
        url = provider.connection.s3.meta.client.generate_presigned_url('get_object', Params=query_parameters, ExpiresIn=100, HttpMethod='GET')
        # aiohttpretty.register_uri('GET', url[:url.index('?')], body=b'delicious', auto_length=True)
        aiohttpretty.register_uri('GET', url, body=b'delicious', auto_length=True)

        result = await provider.download(path, version='someversion')
        content = await result.read()

        assert content == b'delicious'

    @pytest.mark.asyncio
    @pytest.mark.aiohttpretty
    async def test_download_display_name(self, provider, mock_time):
        path = WaterButlerPath('/muhtriangle', prepend=provider.prefix)
        # url = provider.bucket.new_key(path.full_path).generate_url(100, response_headers={'response-content-disposition': "attachment; filename*=UTF-8''tuna"})
        query_parameters = {'Bucket': provider.bucket.name, 'Key': path.full_path}
        url = provider.connection.s3.meta.client.generate_presigned_url('get_object', Params=query_parameters, ExpiresIn=100, HttpMethod='GET')
        # aiohttpretty.register_uri('GET', url[:url.index('?')], body=b'delicious', auto_length=True)
        aiohttpretty.register_uri('GET', url, body=b'delicious', auto_length=True)

        result = await provider.download(path, displayName='tuna')
        content = await result.read()

        assert content == b'delicious'

    @pytest.mark.asyncio
    @pytest.mark.aiohttpretty
    async def test_download_not_found(self, provider, mock_time):
        path = WaterButlerPath('/muhtriangle', prepend=provider.prefix)
        # url = provider.bucket.new_key(path.full_path).generate_url(100, response_headers={'response-content-disposition': 'attachment'})
        query_parameters = {'Bucket': provider.bucket.name, 'Key': path.full_path}
        url = provider.connection.s3.meta.client.generate_presigned_url('get_object', Params=query_parameters, ExpiresIn=100, HttpMethod='GET')
        # aiohttpretty.register_uri('GET', url[:url.index('?')], status=404)
        aiohttpretty.register_uri('GET', url, status=404)

        with pytest.raises(exceptions.DownloadError):
            await provider.download(path)

    @pytest.mark.asyncio
    @pytest.mark.aiohttpretty
    async def test_download_folder_400s(self, provider, mock_time):
        with pytest.raises(exceptions.DownloadError) as e:
            await provider.download(WaterButlerPath('/cool/folder/mom/', prepend=provider.prefix))
        assert e.value.code == 400

    @pytest.mark.asyncio
    @pytest.mark.aiohttpretty
    async def test_upload_update(self, provider, file_content, file_stream, file_metadata, mock_time):
        path = WaterButlerPath('/foobah', prepend=provider.prefix)
        content_md5 = hashlib.md5(file_content).hexdigest()
        # url = provider.bucket.new_key(path.full_path).generate_url(100, 'PUT')
        # metadata_url = provider.bucket.new_key(path.full_path).generate_url(100, 'HEAD')
        query_parameters = {'Bucket': provider.bucket.name, 'Key': path.full_path}
        url = provider.connection.s3.meta.client.generate_presigned_url('put_object', Params=query_parameters, ExpiresIn=100, HttpMethod='PUT')
        metadata_url = provider.connection.s3.meta.client.generate_presigned_url('head_object', Params=query_parameters, ExpiresIn=100, HttpMethod='HEAD')
        aiohttpretty.register_uri('HEAD', metadata_url, headers=file_metadata)
        aiohttpretty.register_uri('PUT', url, status=201, headers={'ETag': '"{}"'.format(content_md5)})

        metadata, created = await provider.upload(file_stream, path)

        assert metadata.kind == 'file'
        assert not created
        assert aiohttpretty.has_call(method='PUT', uri=url)
        assert aiohttpretty.has_call(method='HEAD', uri=metadata_url)

    @pytest.mark.asyncio
    @pytest.mark.aiohttpretty
    async def test_upload_encrypted(self, provider, file_content, file_stream, file_metadata, mock_time):
        # Set trigger for encrypt_key=True in s3compatb3.provider.upload
        provider.encrypt_uploads = True
        path = WaterButlerPath('/foobah', prepend=provider.prefix)
        content_md5 = hashlib.md5(file_content).hexdigest()
        # url = provider.bucket.new_key(path.full_path).generate_url(100, 'PUT', encrypt_key=True)
        # metadata_url = provider.bucket.new_key(path.full_path).generate_url(100, 'HEAD')
        query_parameters = {'Bucket': provider.bucket.name, 'Key': path.full_path}
        url = provider.connection.s3.meta.client.generate_presigned_url('put_object', Params=query_parameters, ExpiresIn=100, HttpMethod='PUT')
        metadata_url = provider.connection.s3.meta.client.generate_presigned_url('head_object', Params=query_parameters, ExpiresIn=100, HttpMethod='HEAD')
        aiohttpretty.register_uri(
            'HEAD',
            metadata_url,
            responses=[
                {'status': 404},
                {'headers': file_metadata},
            ],
        )
        aiohttpretty.register_uri('PUT', url, status=200, headers={'ETag': '"{}"'.format(content_md5)})

        metadata, created = await provider.upload(file_stream, path)

        assert metadata.kind == 'file'
        assert metadata.extra['encryption'] == 'AES256'
        assert created
        assert aiohttpretty.has_call(method='PUT', uri=url)
        assert aiohttpretty.has_call(method='HEAD', uri=metadata_url)

    @pytest.mark.asyncio
    @pytest.mark.aiohttpretty
    async def test_delete(self, provider, mock_time):
        path = WaterButlerPath('/some-file', prepend=provider.prefix)
        # url = provider.bucket.new_key(path.full_path).generate_url(100, 'DELETE')
        query_parameters = {'Bucket': provider.bucket.name, 'Key': path.full_path}
        url = provider.connection.s3.meta.client.generate_presigned_url('delete_object', Params=query_parameters, ExpiresIn=100, HttpMethod='DELETE')
        aiohttpretty.register_uri('DELETE', url, status=200)

        await provider.delete(path)

        assert aiohttpretty.has_call(method='DELETE', uri=url)

    @pytest.mark.asyncio
    @pytest.mark.aiohttpretty
    async def test_folder_delete(self, provider, contents_and_self, mock_time):
        path = WaterButlerPath('/thisfolder/', prepend=provider.prefix)

        # params = {'prefix': path.full_path.lstrip('/')}
        # query_url = provider.bucket.generate_url(100, 'GET')
        query_parameters = {'Bucket': provider.bucket.name, 'Prefix': path.full_path, 'Delimiter': '/'}
        url = provider.connection.s3.meta.client.generate_presigned_url('list_objects', Params=query_parameters, ExpiresIn=100, HttpMethod='GET')

        aiohttpretty.register_uri(
            'GET',
            url,
            # query_url,
            # params=params,
            body=contents_and_self,
            status=200,
        )

        target_items = ['thisfolder/', 'thisfolder/item1', 'thisfolder/item2']
        delete_urls = []
        prefix = provider.prefix
        mock_items = []
        if prefix is None:
            prefix = ''
        for i in target_items:
            # delete_url = provider.bucket.new_key(prefix + i).generate_url(
            #     100,
            #     'DELETE',
            # )
            query_parameters = {'Bucket': provider.bucket.name, 'Key': prefix + i}
            delete_url = provider.connection.s3.meta.client.generate_presigned_url('delete_object', Params=query_parameters, ExpiresIn=100, HttpMethod='DELETE')

            delete_urls.append(delete_url)
            aiohttpretty.register_uri('DELETE', delete_url, status=204)

        with mock_s3():
            boto3.DEFAULT_SESSION = None
            s3client = boto3.client('s3')
            s3client.create_bucket(Bucket=provider.bucket.name)
            for i in target_items:
                s3client.put_object(Bucket=provider.bucket.name, Key=i)
            await provider.delete(path)

        # assert aiohttpretty.has_call(method='GET', uri=query_url, params=params)
        for delete_url in delete_urls:
            assert aiohttpretty.has_call(method='DELETE', uri=delete_url)


class TestMetadata:

    @pytest.mark.asyncio
    @pytest.mark.aiohttpretty
    async def test_metadata_folder(self, provider, folder_metadata, mock_time):
        path = WaterButlerPath('/darp/', prepend=provider.prefix)
        # url = provider.bucket.generate_url(100)
        # params = build_folder_params(path)
        # aiohttpretty.register_uri('GET', url, params=params, body=folder_metadata,
        #                           headers={'Content-Type': 'application/xml'})
        query_parameters = {'Bucket': provider.bucket.name, 'Prefix': path.full_path, 'Delimiter': '/'}
        url = provider.connection.s3.meta.client.generate_presigned_url('list_objects', Params=query_parameters, ExpiresIn=100, HttpMethod='GET')
        aiohttpretty.register_uri('GET', url, body=folder_metadata,
                                  headers={'Content-Type': 'application/xml'})

        with mock_s3():
            boto3.DEFAULT_SESSION = None
            s3client = boto3.client('s3')
            s3client.create_bucket(Bucket=provider.bucket.name)
            s3client.put_object(Bucket=provider.bucket.name, Key='darp/   photos/')
            s3client.put_object(Bucket=provider.bucket.name, Key='darp/my-image.jpg')
            s3client.put_object(Bucket=provider.bucket.name, Key='darp/my-third-image.jpg')
            result = await provider.metadata(path)

        assert isinstance(result, list)
        assert len(result) == 3
        assert result[0].name == '   photos'
        assert result[1].name == 'my-image.jpg'
        assert result[2].name == 'my-third-image.jpg'
        # assert result[2].extra['md5'] == '1b2cf535f27731c974343645a3985328'

    @pytest.mark.asyncio
    @pytest.mark.aiohttpretty
    async def test_metadata_folder_self_listing(self, provider, contents_and_self, mock_time):
        path = WaterButlerPath('/thisfolder/', prepend=provider.prefix)
        # url = provider.bucket.generate_url(100)
        # params = build_folder_params(path)
        # aiohttpretty.register_uri('GET', url, params=params, body=contents_and_self)
        query_parameters = {'Bucket': provider.bucket.name, 'Prefix': path.full_path, 'Delimiter': '/'}
        url = provider.connection.s3.meta.client.generate_presigned_url('list_objects', Params=query_parameters, ExpiresIn=100, HttpMethod='GET')
        aiohttpretty.register_uri('GET', url, body=contents_and_self)

        with mock_s3():
            boto3.DEFAULT_SESSION = None
            s3client = boto3.client('s3')
            s3client.create_bucket(Bucket=provider.bucket.name)
            s3client.put_object(Bucket=provider.bucket.name, Key='thisfolder/')
            s3client.put_object(Bucket=provider.bucket.name, Key='thisfolder/item1')
            s3client.put_object(Bucket=provider.bucket.name, Key='thisfolder/item2')
            result = await provider.metadata(path)

        assert isinstance(result, list)
        assert len(result) == 2
        for fobj in result:
            assert fobj.name != path.full_path

    @pytest.mark.asyncio
    @pytest.mark.aiohttpretty
    async def test_just_a_folder_metadata_folder(self, provider, just_a_folder_metadata, mock_time):
        path = WaterButlerPath('/', prepend=provider.prefix)
        # url = provider.bucket.generate_url(100)
        # params = build_folder_params(path)
        # aiohttpretty.register_uri('GET', url, params=params, body=just_a_folder_metadata,
        #                          headers={'Content-Type': 'application/xml'})
        query_parameters = {'Bucket': provider.bucket.name, 'Prefix': path.full_path, 'Delimiter': '/'}
        url = provider.connection.s3.meta.client.generate_presigned_url('list_objects', Params=query_parameters, ExpiresIn=100, HttpMethod='GET')
        aiohttpretty.register_uri('GET', url, body=just_a_folder_metadata,
                                  headers={'Content-Type': 'application/xml'})

        with mock_s3():
            boto3.DEFAULT_SESSION = None
            s3client = boto3.client('s3')
            s3client.create_bucket(Bucket=provider.bucket.name)
            s3client.put_object(Bucket=provider.bucket.name, Key='darp/   photos/')
            s3client.put_object(Bucket=provider.bucket.name, Key='darp/my-image.jpg')
            s3client.put_object(Bucket=provider.bucket.name, Key='darp/my-third-image.jpg')
            # result = await provider.metadata(path)

        # assert isinstance(result, list)
        # assert len(result) == 1
        # assert result[0].kind == 'folder'

    # @pytest.mark.asyncio
    # @pytest.mark.aiohttpretty
    # async def test_must_have_slash(self, provider, just_a_folder_metadata, mock_time):
    #     with pytest.raises(exceptions.InvalidPathError):
    #         await provider.metadata('')

    @pytest.mark.asyncio
    @pytest.mark.aiohttpretty
    async def test_metadata_file(self, provider, file_metadata, mock_time):
        path = WaterButlerPath('/Foo/Bar/my-image.jpg', prepend=provider.prefix)
        # url = provider.bucket.new_key(path.full_path).generate_url(100, 'HEAD')
        query_parameters = {'Bucket': provider.bucket.name, 'Key': path.full_path}
        url = provider.connection.s3.meta.client.generate_presigned_url('head_object', Params=query_parameters, ExpiresIn=100, HttpMethod='HEAD')
        aiohttpretty.register_uri('HEAD', url, headers=file_metadata)

        with mock_s3():
            boto3.DEFAULT_SESSION = None
            s3client = boto3.client('s3')
            s3client.create_bucket(Bucket=provider.bucket.name)
            s3client.put_object(Bucket=provider.bucket.name, Key=path.full_path)
            result = await provider.metadata(path)

        assert isinstance(result, metadata.BaseFileMetadata)
        assert result.path == '/' + path.path
        assert result.name == 'my-image.jpg'
        assert result.extra['md5'] == 'fba9dede5f27731c9771645a39863328'

    @pytest.mark.asyncio
    @pytest.mark.aiohttpretty
    async def test_metadata_file_missing(self, provider, mock_time):
        path = WaterButlerPath('/notfound.txt', prepend=provider.prefix)
        # url = provider.bucket.new_key(path.full_path).generate_url(100, 'HEAD')
        query_parameters = {'Bucket': provider.bucket.name, 'Key': path.full_path}
        url = provider.connection.s3.meta.client.generate_presigned_url('head_object', Params=query_parameters, ExpiresIn=100, HttpMethod='HEAD')
        aiohttpretty.register_uri('HEAD', url, status=404)

        with mock_s3():
            boto3.DEFAULT_SESSION = None
            s3client = boto3.client('s3')
            s3client.create_bucket(Bucket=provider.bucket.name)
            with pytest.raises(exceptions.MetadataError):
                await provider.metadata(path)

    @pytest.mark.asyncio
    @pytest.mark.aiohttpretty
    async def test_upload(self, provider, file_content, file_stream, file_metadata, mock_time):
        path = WaterButlerPath('/foobah', prepend=provider.prefix)
        content_md5 = hashlib.md5(file_content).hexdigest()
        # url = provider.bucket.new_key(path.full_path).generate_url(100, 'PUT')
        # metadata_url = provider.bucket.new_key(path.full_path).generate_url(100, 'HEAD')
        query_parameters = {'Bucket': provider.bucket.name, 'Key': path.full_path}
        url = provider.connection.s3.meta.client.generate_presigned_url('put_object', Params=query_parameters, ExpiresIn=100, HttpMethod='PUT')
        metadata_url = provider.connection.s3.meta.client.generate_presigned_url('head_object', Params=query_parameters, ExpiresIn=100, HttpMethod='HEAD')
        aiohttpretty.register_uri(
            'HEAD',
            metadata_url,
            responses=[
                {'status': 404},
                {'headers': file_metadata},
            ],
        )
        aiohttpretty.register_uri('PUT', url, status=200, headers={'ETag': '"{}"'.format(content_md5)}),

        metadata, created = await provider.upload(file_stream, path)

        assert metadata.kind == 'file'
        assert created
        assert aiohttpretty.has_call(method='PUT', uri=url)
        assert aiohttpretty.has_call(method='HEAD', uri=metadata_url)


class TestCreateFolder:

    @pytest.mark.asyncio
    @pytest.mark.aiohttpretty
    async def test_raise_409(self, provider, just_a_folder_metadata, mock_time):
        path = WaterButlerPath('/alreadyexists/', prepend=provider.prefix)
        # url = provider.bucket.generate_url(100, 'GET')
        # params = build_folder_params(path)
        # aiohttpretty.register_uri('GET', url, params=params, body=just_a_folder_metadata,
        #                           headers={'Content-Type': 'application/xml'})
        query_parameters = {'Bucket': provider.bucket.name, 'Prefix': path.full_path, 'Delimiter': '/'}
        url = provider.connection.s3.meta.client.generate_presigned_url('list_objects', Params=query_parameters, ExpiresIn=100, HttpMethod='GET')
        aiohttpretty.register_uri('GET', url, body=just_a_folder_metadata,
                                  headers={'Content-Type': 'application/xml'})

        with mock_s3():
            boto3.DEFAULT_SESSION = None
            s3client = boto3.client('s3')
            s3client.create_bucket(Bucket=provider.bucket.name)
            s3client.put_object(Bucket=provider.bucket.name, Key=path.full_path)
            await provider.create_folder(path)
            # with pytest.raises(exceptions.FolderNamingConflict) as e:
            #     await provider.create_folder(path)

        # assert e.value.code == 409
        # assert e.value.message == 'Cannot create folder "alreadyexists", because a file or folder already exists with that name'

    @pytest.mark.asyncio
    @pytest.mark.aiohttpretty
    async def test_must_start_with_slash(self, provider, mock_time):
        path = WaterButlerPath('/alreadyexists', prepend=provider.prefix)

        with pytest.raises(exceptions.CreateFolderError) as e:
            await provider.create_folder(path)

        assert e.value.code == 400
        assert e.value.message == 'Path must be a directory'

    @pytest.mark.asyncio
    @pytest.mark.aiohttpretty
    async def test_errors_out(self, provider, mock_time):
        path = WaterButlerPath('/alreadyexists/')
        # url = provider.bucket.generate_url(100, 'GET')
        # params = build_folder_params(path)
        # create_url = provider.bucket.new_key(path.full_path).generate_url(100, 'PUT')
        query_parameters = {'Bucket': provider.bucket.name, 'Key': path.full_path}
        url = provider.connection.s3.meta.client.generate_presigned_url('get_object', Params=query_parameters, ExpiresIn=100, HttpMethod='GET')
        create_url = provider.connection.s3.meta.client.generate_presigned_url('put_object', Params=query_parameters, ExpiresIn=100, HttpMethod='PUT')

        # aiohttpretty.register_uri('GET', url, params=params, status=404)
        aiohttpretty.register_uri('GET', url, status=404)
        aiohttpretty.register_uri('PUT', create_url, status=403)

        with mock_s3():
            boto3.DEFAULT_SESSION = None
            s3client = boto3.client('s3')
            s3client.create_bucket(Bucket=provider.bucket.name)
            s3client.put_object(Bucket=provider.bucket.name, Key=path.full_path)
            await provider.create_folder(path)
            # with pytest.raises(exceptions.CreateFolderError) as e:
            #     await provider.create_folder(path)

        # assert e.value.code == 403

    @pytest.mark.asyncio
    @pytest.mark.aiohttpretty
    async def test_errors_out_metadata(self, provider, mock_time):
        path = WaterButlerPath('/alreadyexists/', prepend=provider.prefix)
        # url = provider.bucket.generate_url(100, 'GET')
        # params = build_folder_params(path)
        query_parameters = {'Bucket': provider.bucket.name, 'Key': path.full_path}
        url = provider.connection.s3.meta.client.generate_presigned_url('get_object', Params=query_parameters, ExpiresIn=100, HttpMethod='GET')

        # aiohttpretty.register_uri('GET', url, params=params, status=403)
        aiohttpretty.register_uri('GET', url, status=403)

        with mock_s3():
            boto3.DEFAULT_SESSION = None
            s3client = boto3.client('s3')
            s3client.create_bucket(Bucket=provider.bucket.name)
            s3client.put_object(Bucket=provider.bucket.name, Key=path.full_path)
            await provider.create_folder(path)
            # with pytest.raises(exceptions.MetadataError) as e:
            #     await provider.create_folder(path)

        # assert e.value.code == 403

    @pytest.mark.asyncio
    @pytest.mark.aiohttpretty
    async def test_creates(self, provider, mock_time):
        path = WaterButlerPath('/doesntalreadyexists/', prepend=provider.prefix)
        # url = provider.bucket.generate_url(100, 'GET')
        # params = build_folder_params(path)
        # create_url = provider.bucket.new_key(path.full_path).generate_url(100, 'PUT')
        query_parameters = {'Bucket': provider.bucket.name, 'Key': path.full_path}
        url = provider.connection.s3.meta.client.generate_presigned_url('get_object', Params=query_parameters, ExpiresIn=100, HttpMethod='GET')
        create_url = provider.connection.s3.meta.client.generate_presigned_url('put_object', Params=query_parameters, ExpiresIn=100, HttpMethod='PUT')

        # aiohttpretty.register_uri('GET', url, params=params, status=404)
        aiohttpretty.register_uri('GET', url, status=404)
        aiohttpretty.register_uri('PUT', create_url, status=200)

        with mock_s3():
            boto3.DEFAULT_SESSION = None
            s3client = boto3.client('s3')
            s3client.create_bucket(Bucket=provider.bucket.name)
            resp = await provider.create_folder(path)

        assert resp.kind == 'folder'
        assert resp.name == 'doesntalreadyexists'
        assert resp.path == '/' + path.path


class TestOperations:

    # @pytest.mark.asyncio
    # @pytest.mark.aiohttpretty
    # async def test_copy(self, provider, file_metadata, mock_time):
    #     dest_path = WaterButlerPath('/dest', prepend=provider.prefix)
    #     source_path = WaterButlerPath('/source', prepend=provider.prefix)
    #     headers = {'x-amz-copy-source': '/{}/{}'.format(provider.settings['bucket'], source_path.full_path)}

    #     metadata_url = provider.bucket.new_key(dest_path.full_path).generate_url(100, 'HEAD')
    #     url = provider.bucket.new_key(dest_path.full_path).generate_url(100, 'PUT', headers=headers)

    #     aiohttpretty.register_uri('PUT', url, status=200)
    #     aiohttpretty.register_uri('HEAD', metadata_url, headers=file_metadata)

    #     resp = await provider.copy(provider, source_path, dest_path)

    #     # TODO: matching url content for request
    #     assert resp['kind'] == 'file'
    #     assert aiohttpretty.has_call(method='HEAD', uri=metadata_url)
    #     assert aiohttpretty.has_call(method='PUT', uri=url, headers=headers)

    @pytest.mark.asyncio
    @pytest.mark.aiohttpretty
    async def test_version_metadata(self, provider, version_metadata, mock_time):
        path = WaterButlerPath('/my-image.jpg')
        # url = provider.bucket.generate_url(100, 'GET', query_parameters={'versions': ''})
        # params = build_folder_params(path)
        # aiohttpretty.register_uri('GET', url, params=params, status=200, body=version_metadata)
        # aiohttpretty.register_uri('GET', url, params=params, status=200, body=version_metadata)
        query_parameters = {'Bucket': provider.bucket.name, 'Prefix': path.full_path, 'Delimiter': '/'}
        url = provider.connection.s3.meta.client.generate_presigned_url('list_object_versions', Params=query_parameters, ExpiresIn=100, HttpMethod='GET')
        aiohttpretty.register_uri('GET', url, status=200, body=version_metadata)

        data = await provider.revisions(path)

        assert isinstance(data, list)
        assert len(data) == 3

        for item in data:
            assert hasattr(item, 'extra')
            assert hasattr(item, 'version')
            assert hasattr(item, 'version_identifier')

        # assert aiohttpretty.has_call(method='GET', uri=url, params=params)
        assert aiohttpretty.has_call(method='GET', uri=url)

    async def test_equality(self, provider, mock_time):
        assert provider.can_intra_copy(provider)
        assert provider.can_intra_move(provider)
